# Building a multi-agent AI platform on FastAPI without regret

**PydanticAI is the strongest fit for a FastAPI + PostgreSQL + Redis + Taskiq stack**, offering type-safe agent definitions, dependency injection that mirrors FastAPI patterns, V1 API stability, and true provider agnosticism — while LangGraph remains the most mature option for complex stateful workflows requiring durable checkpointing and graph-based orchestration. The Microsoft ecosystem (Semantic Kernel, AutoGen) entered maintenance mode in October 2025 and should be avoided for new Python projects. The most important architectural insight from Anthropic, OpenAI, and real-world production teams is unanimous: **start with the simplest pattern that works** — a single agent with tool calling — and add multi-agent orchestration only when a concrete need emerges. Your existing BFF skeleton (Taskiq workers, Redis Streams consumer groups, centralised LLM service) already provides most of the infrastructure needed for an agent execution layer; the framework choice primarily adds tool calling orchestration, conversation management, and developer ergonomics on top.

## The framework landscape has consolidated around three real contenders

After evaluating nine frameworks against the specific constraints of FastAPI + async SQLAlchemy + Redis + Taskiq + dual deployment (Azure App Service / bare-metal Ubuntu), only three merit serious consideration for a new production system in 2026. The rest are either entering maintenance mode, pre-1.0 with significant lock-in risk, or optimised for different ecosystems.

**PydanticAI (V1, September 2025)** is built by the same team behind Pydantic, the validation library that already underpins FastAPI, the OpenAI SDK, and the Anthropic SDK. It reached V1 with an explicit API stability guarantee — no breaking changes until V2. The design philosophy is "the FastAPI feeling for GenAI": agents are generic on dependency and output types (`Agent[SupportDeps, SupportOutput]`), tools are decorated functions with automatic schema generation from type hints, and a first-class dependency injection system via `RunContext[DepsType]` maps directly to FastAPI's `Depends()` pattern. Provider support is the broadest of any framework — native implementations for OpenAI, Anthropic, Azure OpenAI, Google, Bedrock, Mistral, and a dozen others, with no proxy layer required. MCP support is comprehensive (client and server), human-in-the-loop is production-ready via tool approval mechanisms, and durable execution integrates with Temporal. The graph/workflow module (`pydantic_graph`) supports steps, joins, parallel execution, and persistence, though its builder API remains in beta. With **15 million+ downloads** and 100% test coverage, this is the least-hyped and most production-mature lightweight framework.

**LangGraph (1.0 GA, October 2025)** is the strongest choice when you need durable, checkpointed, graph-based agent workflows — the kind required for a multi-turn chatbot with tool calling, human-in-the-loop approval gates, and multi-day agent tasks. It models workflows as directed state graphs where nodes are Python functions and edges control flow. The killer feature is its **native PostgreSQL checkpointer** (`AsyncPostgresSaver` via psycopg3): state is saved automatically after every graph step, enabling time-travel debugging, interrupt/resume for human approval, and recovery from crashes. Multi-agent patterns are well-supported through LangGraph Supervisor (hierarchical) and LangGraph Swarm (handoff) libraries. Async Python support is excellent, and FastAPI integration is well-documented with multiple production reference implementations. Companies including Uber, LinkedIn, Elastic, Replit, and Qualtrics run LangGraph in production. The core library is MIT-licensed with **no lock-in** to LangGraph Platform or LangSmith. The critical caveat: its PostgreSQL checkpointer uses psycopg3 directly, **not SQLAlchemy** — you'll operate two separate connection management systems.

**The custom approach using raw SDKs** remains viable and is explicitly endorsed by Anthropic's engineering team. Their December 2024 guide states: *"The most successful implementations weren't using complex frameworks. Instead, they were building with simple, composable patterns."* A complete custom agent orchestration layer — tool calling loop, conversation persistence, human-in-the-loop, checkpointing, and multi-agent routing — requires approximately **1,000–2,000 lines** of well-structured Python. The main cost is reimplementing structured output validation, retry logic, and observability tracing that frameworks provide for free. This approach offers zero dependency risk and perfect alignment with your existing architecture, but the maintenance burden accumulates as agent complexity grows.

**Frameworks to avoid for this stack:**

- **Semantic Kernel**: Entered maintenance mode October 2025. Microsoft is merging it into "Microsoft Agent Framework" (GA planned Q1 2026). Python SDK always lagged the C# version. Building on it now means an immediate forced migration.
- **AutoGen / AG2**: Three incompatible branches exist (AutoGen v0.4, AG2, Microsoft Agent Framework). Also entering maintenance mode. The v0.2→v0.4 rewrite and AG2 fork caused significant community fragmentation.
- **CrewAI**: Active and well-funded (~$18M raised, **40,700 GitHub stars**), but its role-based model breaks down for complex stateful workflows. Async support has been a recurring source of bugs. No built-in PostgreSQL persistence or checkpointing. Better for rapid prototyping than for integration into an existing async FastAPI architecture.
- **OpenAI Agents SDK**: Pre-1.0 (v0.8.4), with breaking changes between minor versions. The handoff pattern is genuinely excellent, but the SDK is optimised for OpenAI's message format, and hosted tools (FileSearch, WebSearch, CodeInterpreter) are OpenAI-only. Provider lock-in is medium despite LiteLLM integration.
- **Google ADK**: Pre-1.0 (v0.5.0), Google Cloud-centric. No specific Azure deployment support. Ambitious feature set but too immature and ecosystem-misaligned for an Azure-targeting stack.

| Criterion | PydanticAI | LangGraph | Custom | CrewAI | OpenAI Agents |
|---|---|---|---|---|---|
| **Version / Stability** | V1 (stable) | 1.0 GA | N/A | 1.1.0 | v0.8 (pre-1.0) |
| **FastAPI alignment** | ★★★★★ | ★★★★ | ★★★★★ | ★★★ | ★★★★ |
| **Async-native** | ★★★★★ | ★★★★★ | ★★★★★ | ★★★ | ★★★★ |
| **PostgreSQL persistence** | Via Temporal | Native checkpointer | Build yourself | None | None |
| **Human-in-the-loop** | Tool approval | First-class `interrupt` | Build yourself | Manual | Documented |
| **Provider lock-in** | Very low | Low | None | Low | Medium |
| **Multi-agent maturity** | Moderate | Strong | Build yourself | Strong | Strong |
| **Abstraction tax** | Low | Moderate | None | Low–Moderate | Low |
| **Maintenance risk** | Low (V1 guarantee) | Low (1.0 GA) | High (you own it) | Medium | High (pre-1.0) |

## Architecture patterns that work in production

The multi-agent architecture literature converged on a clear hierarchy of patterns, ordered by increasing complexity. The critical insight from both Anthropic and production teams is that **most agent systems in production are hybrid** — deterministic flows with LLM-driven decisions at specific branch points, not fully autonomous agents.

**The orchestrator pattern is the production default.** A central coordinator receives requests, routes to specialist agents, collects results, and synthesises responses. Routing can be rule-based (keyword/intent matching — cheaper, faster, predictable), LLM-based (flexible but adds a model call per interaction), or hybrid. For your platform, this maps naturally: a FastAPI endpoint receives user input, an orchestrator agent classifies it, and dispatches to the appropriate specialist via the existing service layer. Google's ADK documentation, Microsoft's Azure Architecture Center, and Anthropic's guide all converge on this as the recommended starting point for **3–10 specialist domains**.

**Event-driven agents map directly to Redis Streams consumer groups.** Each agent type becomes a consumer group on relevant streams. The partition key is the conversation/session ID (ensuring message ordering per conversation). Consumer groups provide at-least-once delivery, load balancing across agent instances, and automatic failover via `XAUTOCLAIM` (Redis 6.2+). The pattern: events flow through Redis Streams → consumer groups route to agent workers (Taskiq tasks or direct consumers) → results write back to streams or PostgreSQL. This is ideal for reactive agents that respond to API events, webhook triggers, or cross-agent coordination.

**The swarm/handoff pattern works best for conversation routing.** Originated by OpenAI's experimental Swarm library and now productionised in the Agents SDK, this pattern uses two primitives: agents (instructions + tools) and handoffs (agent-to-agent transfers). An agent locally decides when to transfer control by returning a `transfer_to_specialist()` function call. This is optimal for customer service triage, domain-specific chatbots, and scenarios where no single agent needs centralised control. The risk is ping-pong loops between agents without clear termination conditions — always implement a maximum handoff counter.

**Shared context requires explicit architecture.** Microsoft's multi-agent reference architecture defines two memory tiers: **short-term memory** (session-scoped conversation history in Redis for fast access) and **long-term memory** (cross-session knowledge in PostgreSQL, optionally with pgvector for semantic retrieval). The blackboard pattern — where multiple specialist agents contribute partial solutions to a shared workspace — works well for exploratory or creative tasks but requires conflict resolution for concurrent writes.

## How agents integrate with the existing BFF skeleton

The strongest architectural decision is to run all agents in a **single monolithic FastAPI application** with Taskiq workers from the same codebase. For a team of 1–3 developers, this eliminates the operational overhead of microservices while providing all the execution patterns needed. Split to microservices only when a specific agent has fundamentally different scaling or security requirements.

**Agent execution unifies through a single `AgentExecutor` class** that all trigger types flow through — user-initiated (FastAPI endpoint), scheduled (Taskiq cron task), and event-driven (Redis Streams consumer). This ensures consistent observability, error handling, and cost attribution regardless of how an agent was triggered. The executor loads agent configuration from PostgreSQL, instantiates the appropriate agent with its tools and dependencies, runs it with tracing, and records the result.

**Taskiq is the ideal execution layer** and a significant advantage of your existing stack. Unlike Celery, Taskiq is async-native — critical for LLM API calls that are inherently I/O-bound. Its `RedisStreamBroker` aligns with your existing Redis Streams infrastructure, providing durable task delivery with acknowledgments. The `taskiq-fastapi` package enables Taskiq workers to reuse FastAPI dependencies (database sessions, service instances), so agent tasks share the same service layer as API endpoints. Scheduled agents use Taskiq's `ListRedisScheduleSource` (which supports runtime schedule updates — important for user-configured agents). Background agent processing and event-driven consumers run as Taskiq tasks, giving you retry logic, timeouts, and priority queues for free.

**Agent configuration uses a hybrid model:** metadata (name, description, model, schedule, trigger type, tool permissions) lives in PostgreSQL for runtime updates and admin UI integration, while agent logic lives in Python classes for testability and expressiveness. This avoids the declarative configuration trap — YAML-defined agents break down quickly when you need custom error handling, dynamic prompt generation, or stateful workflow branching.

The integration with your **existing centralised LLM service layer** deserves careful design. Two clean approaches exist. First, if using PydanticAI, configure it to use your LLM service as a custom model provider — PydanticAI calls your service, which handles prompt templates, cost tracking, and circuit breaking. Second, if using LangGraph, use LangChain's provider abstraction but wrap your circuit breaker and cost tracking as middleware. Either way, the framework's tool-calling loop should delegate LLM invocation to your existing service, not bypass it.

**A practical phased build path:**

- **Phase 1**: Single-agent foundation. One FastAPI endpoint, one agent type (e.g., news digest), PydanticAI for tool calling, PostgreSQL for conversation storage, Langfuse `@observe()` decorator from day one.
- **Phase 2**: Add background and scheduled agents. Taskiq workers with `RedisStreamBroker`, scheduled news digest via cron, background processing for long-running agent tasks.
- **Phase 3**: Event-driven agents. Redis Streams consumer groups, agents reacting to SailPoint webhook events or API triggers.
- **Phase 4**: Multi-agent orchestration. Router/triage agent dispatching to specialists, human-in-the-loop approval gates, LangGraph for complex stateful workflows that need durable checkpointing.

## Tools, MCP, and the service layer boundary

**MCP (Model Context Protocol) is the de facto standard for AI-to-tool connectivity** and should be adopted for external integrations. Originally introduced by Anthropic in November 2024, MCP was donated to the **Agentic AI Foundation** under the Linux Foundation in December 2025, co-founded by Anthropic, OpenAI, and Block, with support from AWS, Google, Microsoft, and Cloudflare. It has **97 million monthly SDK downloads**, over 10,000 active servers, and is supported by every major agent framework (LangChain, PydanticAI, OpenAI Agents SDK, Google ADK, CrewAI). This is no longer "one of many competing approaches" — it won.

MCP defines tools as JSON-RPC 2.0 endpoints with JSON Schema parameters, descriptions for the LLM, and behavioural annotations (read-only vs. destructive). For your platform, the key architectural decision is: **use MCP for external tool connectivity (SailPoint IdentityNow, third-party APIs) and native framework tools for internal service-layer calls**. This keeps the service boundary clean — internal tools use PydanticAI's dependency injection to call services, while external integrations are MCP servers that can be developed, tested, and deployed independently.

MCP's main limitations are security-related: no built-in authentication standard, susceptibility to tool poisoning and prompt injection via tool descriptions, and token overhead from loading all tool definitions upfront. Anthropic's engineering team recommends **lazy tool loading** (agents search for and load tool definitions on demand) and code execution as mitigations.

**The critical architectural rule is that tools call services, never repositories or APIs directly.** PydanticAI's dependency injection enforces this elegantly:

```python
@dataclass
class AgentDeps:
    identity_service: IdentityService  # Your existing service
    permission_service: PermissionService

@agent.tool
async def lookup_identity(ctx: RunContext[AgentDeps], email: str) -> str:
    """Look up an identity in SailPoint by email."""
    return await ctx.deps.identity_service.find_by_email(email)
```

This pattern means agents interact with the same service layer as your FastAPI endpoints, preserving business logic encapsulation, audit logging, and access control. Import linting rules (via `import-linter`) can enforce that the tools module never imports from repositories or external clients directly.

**For SailPoint IdentityNow specifically**, the integration surface is well-defined: a RESTful v3 API with OAuth 2.0 authentication, Elasticsearch-based search, and an event trigger system for webhooks. Build custom MCP tools wrapping the key operations (identity search, access request, certification management, entitlement review), and use SailPoint's event triggers as webhook inputs to Redis Streams, where event-driven agents can react to identity lifecycle events. SailPoint launched **Harbor Pilot** (March 2025), their own AI agent product built on Amazon Bedrock — studying its capabilities will reveal what operations are most valuable to automate.

## Production concerns that frameworks won't solve for you

**Rate limiting and cost control require a dedicated proxy layer.** LiteLLM Proxy is the standard solution: an OpenAI-compatible proxy supporting 100+ LLM providers with **granular budgets** (per-key, per-agent, per-team, per-model, per-day) and rate limits (RPM, TPM, max parallel requests). It's Redis-backed for multi-instance synchronisation and integrates with Langfuse for unified observability. The setup is straightforward: create a per-agent API key with budget and rate limit constraints, route all LLM calls through the proxy. If your existing centralised LLM service already handles circuit breaking and cost tracking, LiteLLM can sit behind it or replace the provider-routing component — evaluate which adds less duplication. Tag every request with `agent_id` metadata for cost attribution.

**Observability must be instrumented from day one.** Langfuse (open-source, self-hostable, OpenTelemetry-native in v3) is the strongest option for LLM-specific observability. The `@observe()` decorator auto-traces any Python function, nesting LLM calls, tool executions, and sub-agent invocations into hierarchical traces. Token usage and cost are calculated per generation and aggregatable per agent, per user, per session. Since Langfuse v3 is built on the official OpenTelemetry Python client, traces from your FastAPI middleware, database queries, and Redis operations appear in the same trace context — giving you end-to-end visibility from HTTP request to LLM response to tool execution. Alternative: Pydantic Logfire (also OTEL-native, deeper PydanticAI integration, but commercially operated).

**State management splits into two distinct problems.** Short-lived conversational state (chatbot turns, active workflow context) belongs in Redis for sub-millisecond access and automatic expiry. Long-lived durable state (multi-day agent tasks, checkpoint recovery, audit trails) belongs in PostgreSQL. LangGraph's PostgreSQL checkpointer handles the latter elegantly for graph-based workflows; for PydanticAI, integrate with Temporal for durable execution or implement a simpler checkpoint table yourself. The key design principle: **every agent step must be idempotent** so retries from checkpoints don't produce duplicate side effects.

**Testing multi-agent systems follows a four-tier hierarchy.** Unit tests verify individual agents produce correct tool calls for given inputs — PydanticAI provides a built-in `TestModel` that returns predictable responses without hitting LLM APIs. Integration tests verify agent handoffs and workflow correctness using mocked tool responses. System tests run full workflows against staging LLM endpoints. Evaluation tests use LLM-as-a-judge (via Langfuse Datasets or Braintrust) to assess output quality, hallucination, and faithfulness at scale. Budget **80% of testing effort on unit and integration tests** where determinism is achievable.

**Security requires treating each agent as a separate security principal.** The OWASP AI Agent Security Cheat Sheet recommends scoped credentials (each agent gets its own API keys with least-privilege permissions), tool-level access control (PydanticAI's `prepare_tools` filters available tools per agent per step based on permissions), signed inter-agent messages for trust verification, and continuous behavioural monitoring for anomalous tool call patterns. The highest-impact threat is **prompt injection escalating to tool abuse** — mitigate by implementing human-in-the-loop approval for destructive operations (SailPoint access revocations, account modifications), separating data plane from control plane in prompts, and validating all tool outputs against expected schemas before acting on them.

## The recommended approach

**Use PydanticAI as the primary agent runtime** for tool calling, structured outputs, provider abstraction, and dependency injection. It aligns perfectly with the existing FastAPI + Pydantic + async stack, imposes minimal abstraction overhead, and its V1 stability guarantee reduces migration risk. Define simple agents (news scraper, digest generator) as PydanticAI agents with scheduled execution via Taskiq. Define interactive agents (chatbots) as PydanticAI agents with streaming responses via FastAPI WebSocket endpoints.

**Adopt LangGraph selectively for complex stateful workflows** that require durable checkpointing, graph-based control flow, and built-in interrupt/resume for human-in-the-loop. The SailPoint-integrated chatbot — with multi-turn conversation, tool calling for identity operations, and approval gates for sensitive actions — is a strong candidate. LangGraph's `AsyncPostgresSaver` provides production-grade state persistence, and its `interrupt` primitive cleanly implements the approval flow. Accept the operational cost of running psycopg3 alongside SQLAlchemy — it's a manageable trade-off for battle-tested durability.

**Keep the existing centralised LLM service as the foundation.** PydanticAI's model abstraction can delegate to your service (implementing it as a custom model provider) or run alongside it, with your service handling prompt templates, cost tracking, and circuit breaking while PydanticAI handles tool calling orchestration and structured output validation.

**Use MCP for external tool connectivity, Taskiq for execution, Redis Streams for events, and Langfuse for observability.** This leverages every component of the existing skeleton without requiring rewrites. MCP servers for SailPoint and other enterprise APIs can be developed and deployed independently. Taskiq handles scheduled and background agent execution with native async. Redis Streams consumer groups power event-driven agents. Langfuse traces everything.

**Avoid the framework trap by investing in framework-agnostic layers.** Tools are plain Python functions that call your service layer — they work with PydanticAI, LangGraph, or raw SDK calls. Business logic lives in services, not in agent definitions. Conversation history is stored in your PostgreSQL schema, not in a framework-specific format. Observability uses OpenTelemetry, not vendor-specific tracing. If a framework becomes abandonware, your business logic, service layer, tools, and data survive intact — you only rewrite the thin orchestration layer.

## Conclusion

The agent framework landscape in early 2026 has matured enough that two frameworks — PydanticAI and LangGraph — are genuinely production-ready, stable, and architecturally sound for a FastAPI + PostgreSQL + Redis stack. The Microsoft ecosystem should be avoided until Agent Framework reaches GA and proves itself. The most important lesson from companies running agents in production (Uber, LinkedIn, Elastic, Replit) is that **the framework matters less than the architecture around it**: clean service boundaries, durable state management, comprehensive observability, and incremental complexity. Start with a single PydanticAI agent running a daily news digest via Taskiq, prove the execution pipeline end-to-end, then layer in LangGraph for the SailPoint chatbot when you need durable checkpointing and human-in-the-loop. The existing BFF skeleton is not just compatible with this approach — it's ahead of most teams who lack async task execution, event streaming, and centralised LLM management before writing their first agent.