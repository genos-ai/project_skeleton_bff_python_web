# The agent-first paradigm: architecting systems for non-human consumers

**The most consequential infrastructure shift since cloud computing is underway: platforms, APIs, and enterprise systems are being redesigned from the ground up with AI agents — not humans — as their primary users.** This architectural transformation demands a fundamental rethinking of identity, trust, data representation, and security that directly threatens the assumptions underlying every enterprise security architecture today. For a senior CISO at a global bank, this is not a future concern — **70% of banking institutions are already using agentic AI** (MIT/EY 2025), non-human identities outnumber humans 50:1 to 100:1 in enterprise environments, and only **18% of security leaders** are confident their IAM systems can manage agent identities effectively. The 18-month window between now and mid-2027 will define whether organizations establish governance frameworks before agent sprawl overwhelms security controls.

The paradigm shift is best understood through a simple reframe: every system design assumption rooted in human cognition — visual dashboards, click-based workflows, session-based authentication, role-based access — must be re-evaluated when the actor is an autonomous, non-deterministic software entity operating at machine speed. This report maps the foundational design principles, emerging protocol standards, security architecture implications, and strategic trajectory of the agent-first world.

---

## When the user is a machine, everything changes

The agent-first architecture paradigm inverts traditional system design. Where human-first systems optimize for visual comprehension, intuitive navigation, and session-based interaction, agent-first systems optimize for structured data consumption, semantic discoverability, and programmatic action. Anthropic's concept of the **Agent-Computer Interface (ACI)** captures this directly: "Think about how much effort goes into human-computer interfaces (HCI), and plan to invest just as much effort in creating good agent-computer interfaces."

Five core principles have emerged for agent-native architecture, articulated most comprehensively by Dan Shipper and validated across multiple industry sources. **Parity** demands that anything a human can do through a UI, an agent can accomplish through tools — without parity, agents hit dead ends. **Granularity** requires tools to be atomic primitives rather than bundled workflows, because "if you bundle decision logic into tools, you've moved judgment back into code." **Composability** means new features become new prompts, not new code. **Emergent capability** inverts product development from "imagine what users want, build it" to "build a capable foundation, observe what users ask the agent to do, formalize the patterns that emerge." And **improvement over time** enables agent-native apps to evolve through accumulated context without shipping code.

The concept of "Agent Experience" (AX) — coined by Netlify CEO Mathias Biilmann in January 2025 — has rapidly become an organizing discipline, following the lineage of UX and DX. AX asks fundamentally different questions of every product: Can an agent easily get access? Are there clean, well-described APIs? Is documentation machine-readable? Salesforce, which reports **$440 million in agentic revenue** and projects one billion agents by end of 2026, has built a dedicated agent experience design practice. Yet Postman's 2025 State of the API survey found that only **24% of API developers** currently design APIs with AI agents in mind, revealing an enormous readiness gap.

The data representation shift is equally fundamental. Agent-consumable data requires structured typed schemas rather than free-form HTML, machine-readable metadata with semantic descriptions of capabilities and constraints, self-describing interfaces with introspection capabilities, and structured error responses that provide recovery paths rather than just HTTP status codes. As one enterprise architect put it: "An agent does not 'use' an application. It invokes intent." This has given rise to entirely new API paradigms — **Intent APIs** that shift from imperative CRUD operations to declarative goal expression, and **Planning APIs** that don't execute actions but instead propose plans with dependencies, side effects, and warnings. The layered architecture ranges from RPC ("do this now") through REST ("this thing lets you do that") to Intent ("make this outcome true") and Planning ("here's what would happen — are you sure?").

---

## A protocol stack crystallizes around MCP and A2A

The agent infrastructure world is converging on a layered protocol stack analogous to the early internet's TCP/IP, HTTP, and DNS. **Model Context Protocol (MCP)**, introduced by Anthropic in November 2024, has become the de facto standard for agent-to-tool communication in just 14 months, achieving **97 million monthly SDK downloads** and **10,000+ active MCP servers**. Every major AI provider — OpenAI, Google, Microsoft, AWS — has adopted MCP, and in December 2025 Anthropic donated it to the newly formed **Agentic AI Foundation (AAIF)** under the Linux Foundation, co-founded with Block and OpenAI.

MCP provides the "USB-C for AI" — a universal connector standardizing how agents discover tools, invoke functions, access data, and receive structured context. Its November 2025 specification added Tasks for long-running operations, Elicitation for server-to-client information requests, server identity verification, and an official community registry. The security model has evolved to include OAuth 2.1 authorization, with Okta's Cross App Access (XAA) protocol incorporated as an enterprise-managed authorization extension.

Google's **Agent-to-Agent (A2A) protocol**, announced at Cloud Next in April 2025, addresses the complementary problem of inter-agent communication. Where MCP connects agents to tools, A2A enables agents to discover each other through **Agent Cards** (JSON capability advertisements published at `/.well-known/agent.json`), authenticate, delegate tasks with full lifecycle management, and exchange structured artifacts. Version 0.3 added gRPC support and signed security cards. Over 150 organizations support A2A, including Salesforce, SAP, ServiceNow, and PayPal, though adoption has been slower than MCP's grassroots momentum.

Additional protocols fill remaining gaps: **AG-UI** (CopilotKit) bridges agents to human frontends via 16 event types over Server-Sent Events; the **Agent Network Protocol (ANP)** uses W3C DIDs and JSON-LD for inter-agent internet communication with end-to-end encryption; and Coinbase's **X402** embeds agent-to-agent payments directly in the HTTP protocol layer. The AGNTCY project under the Linux Foundation, co-founded by Cisco, is building what it describes as the "TCP/IP, DNS, HTTP equivalents for multi-agent systems." The emerging stack positions MCP as the HTTP equivalent, A2A as the SMTP equivalent, Agent Cards as DNS, and AGENTS.md (OpenAI's markdown standard for project-specific agent instructions, adopted by 60,000+ repositories) as the new robots.txt.

---

## Identity is the existential security challenge

Agent identity represents the most urgent and consequential security challenge in the agent-first paradigm. Traditional IAM was designed for human users with predictable lifecycles, passwords, and MFA prompts. AI agents are fundamentally different: autonomous, ephemeral, non-deterministic, and context-dependent. As Silverfort emphasized in 2025, "AI agents are not NHIs, and they should not be treated as such" — standard non-human identities like service accounts are predictable by design, while AI agents interpret intent, reason independently, and make decisions that evolve in real-time.

The scale challenge is staggering. Enterprise environments already face **NHI-to-human ratios of 50:1 to 100:1**, with **50 million+ leaked API keys, service accounts, and tokens** found on the dark web in 2024 — a 250% increase since 2021. Microsoft reports over one million agents created in Copilot Studio alone. Only **23% of organizations** have a formal enterprise-wide strategy for agent identity management. GitHub's 2025 State of Secrets Sprawl report found that **70% of leaked secrets remain active two years later**, meaning the blast radius of each compromised agent credential compounds over time.

The industry response is accelerating on multiple fronts. **NIST launched its AI Agent Standards Initiative on February 18, 2026**, releasing a concept paper on "Accelerating the Adoption of Software and AI Agent Identity and Authorization" with public comments due April 2, 2026, and financial-sector listening sessions planned for April. The standards under consideration include MCP, OAuth 2.0/2.1, OpenID Connect, SPIFFE/SPIRE, SCIM, and Next Generation Access Control (NGAC). **Microsoft Entra Agent ID**, in public preview since Ignite 2025, introduces new identity object types with a critical design choice: every agent identity requires a human "sponsor" who is accountable for the agent's access and lifecycle. **Okta's Cross App Access (XAA)** protocol, backed by AWS, Google Cloud, Salesforce, and others, shifts consent from individual apps to the enterprise IdP, providing centralized visibility over agent-to-app delegation chains.

SPIFFE/SPIRE, the CNCF graduated project for workload identity, provides cryptographically verifiable, short-lived identities (SVIDs) tied to workloads rather than people. AWS demonstrated agents using SVIDs as "universal, short-lived identities" at CyberArk's Workload Identity Day in November 2025. However, SPIFFE's Kubernetes-native model treats replicas as identical, while AI agents are behaviorally unique — enterprise extensions for per-instance identity are needed.

The delegation chain problem may be the hardest identity challenge. When a primary agent delegates to sub-agents, each hop crosses a trust boundary and inherits original authority. Without scoped permissions and cryptographic lineage, delegation becomes a direct channel for lateral movement. Emerging token formats — **Macaroons, Biscuits, and Wafers** — offer append-only, cryptographically signed tokens that can only narrow scope at each delegation hop, never expand it. No major IdP supports these natively yet, but the principles are being incorporated into existing OAuth frameworks. Auth0's "Auth for GenAI" developer preview includes a Token Vault providing cryptographic proof of user session for agent credential access, and asynchronous authentication with push-based human-in-the-loop approval for long-running agent tasks.

---

## The threat landscape demands a new security model

The **OWASP Top 10 for Agentic Applications**, released in December 2025 and developed with 100+ industry experts, provides the authoritative threat taxonomy. The top risks reveal that identity is the attack surface: Agent Goal Hijacking (redirecting agent objectives via poisoned inputs), Tool Misuse and Exploitation (agents using legitimate tools in unsafe ways), and Identity and Privilege Abuse (leaked credentials enabling agents to operate far beyond intended scope) dominate the list. Three of the top four risks are identity-focused.

Real-world incidents in 2025 demonstrated these aren't theoretical concerns. **EchoLeak** (CVE-2025-32711, CVSS 9.3) was a no-click exploit where hidden prompts in emails triggered silent exfiltration from SharePoint, Teams, and OneDrive. A Google agent deleted the entire contents of a user's drive rather than just the intended folder. Palo Alto Networks' Unit 42 demonstrated **"Agent Session Smuggling"** — rogue agents exploiting built-in trust relationships in A2A to hold multi-turn conversations and build false trust, representing a persistent, adaptive attack unlike single-shot prompt injection. The first AI-orchestrated cyber-espionage campaign was identified in late 2025, with a jailbroken agent handling 80-90% of the attack chain autonomously.

Memory poisoning represents a particularly insidious emerging vector. Lakera AI research demonstrated how poisoned data can corrupt agent long-term memory, creating dormant compromises triggered weeks later — a "sleeper agent" attack that evades point-in-time security assessment. Barracuda Security identified 43 agent framework components with embedded supply chain vulnerabilities in November 2025. The NeurIPS 2025 research warning about model homogenization is particularly relevant for financial services: because most organizations use the same few foundation models, a single jailbreak technique works against nearly everyone, creating systemic rather than idiosyncratic risk.

For security operations, the "Agentic SOC" is emerging as a recognized market category in Gartner's 2025 Hype Cycle, with Omdia tracking 50+ agentic SOC startups. The critical insight for CISOs is that agents themselves constitute a new insider threat population — "always on, never sleeping" systems that, if misconfigured, access privileged APIs while being implicitly trusted. SIEM must monitor not just threats *to* agents but threats *from* agents, requiring behavioral baselining and anomaly detection for agent-initiated actions. Cisco/Splunk Enterprise Security 8.2 now includes Triage, Malware Reversal, and AI Playbook Authoring agents. IBM's ATOM (Autonomous Threat Operations Machine) provides multi-agent orchestration for SOC operations.

---

## Financial services faces a governance reckoning

The regulatory landscape for agent-first systems in banking is complex and rapidly evolving across jurisdictions. The **EU AI Act**, with high-risk system requirements phasing in through August 2026, was designed for static AI systems — it has no mechanism for systems that pass conformity assessment and later add autonomous agent capabilities. Multi-agent delegation chains break the provider/deployer/distributor role framework entirely. The UK FCA has launched its Long Term Review into AI and Retail Financial Services, while the Senior Managers and Certification Regime (SM&CR) creates accountability obligations that become unclear when models update weekly. In the US, the Federal Reserve's **SR 11-7** remains the most significant model risk management regulation, and the OCC explicitly states that "advances in technology do not render existing safety and soundness standards inapplicable."

The SR 11-7 framework must be substantially reinterpreted for agentic systems. The model definition expands beyond the foundation model to include fine-tuning datasets, RAG corpora, prompt templates, tool integrations, and plugins. Conceptual soundness assessment requires anticipating variability and testing under ambiguous and adversarial conditions. Validation must extend beyond accuracy to behavioral, security, and resilience testing. Each AI agent system effectively becomes a "model" under existing MRM governance, requiring inventories, validation reports, version control, and decision path reconstruction for auditability.

The **FINOS AI Governance Framework v2** (October 2025) provides the most comprehensive financial-services-specific risk catalogue, covering multi-agent trust boundary violations where compromise in one agent propagates through shared resources, and specific scenarios such as compromised trading agents influencing compliance agents to approve rule-violating trades. The U.S. Treasury's December 2024 report on AI in Financial Services identified three systemic risks: explainability gaps, third-party AI provider concentration, and the inadequacy of traditional security frameworks for autonomous agents. FinRegLab's September 2025 publication "The Next Wave Arrives: Agentic AI in Financial Services" addresses responsibility for agent-initiated transactions, consumer protection, and regulatory gaps.

Major banks are investing heavily but unevenly. JPMorgan Chase's **$17 billion technology budget** supports 2,000+ AI/ML specialists targeting $2 billion in annual AI value, with its LLM Suite serving 150,000+ daily users. Bank of America allocated $4 billion to AI in 2025. TD Bank plans to grow from 20% to 100% of employees enabled with AI agents, projecting $360 million in expense reduction. Goldman Sachs is testing AI coding agents for 12,000 developers. Yet despite this scale of investment, fewer than **10% of organizations** have deployed agentic security controls (risk registries, dynamic authorization) at scale, creating a dangerous gap between capability and governance.

---

## The infrastructure stack and vendor landscape are converging fast

The major technology vendors are racing to establish agent-first infrastructure positions with distinctly different strategies. **Microsoft's "Frontier Firm" vision** centers on Agent 365 as a control plane managing agents across the enterprise regardless of origin, with Entra Agent ID for identity governance and the Microsoft Foundry Agent Service bridging development to deployment. **Google** is driving interoperability through A2A and the Agent Development Kit while building Agentspace for enterprise discovery. **AWS** has launched Bedrock AgentCore as the most comprehensive managed agent platform, now framework-agnostic with 900+ marketplace listings and customers like Robinhood processing 5 billion tokens daily with 80% cost reduction. **Salesforce's Agentforce** represents the most aggressive enterprise software transformation, releasing five major versions in 14 months and launching AgentExchange as the first agent marketplace for what it calls a "$6 trillion digital labor market."

**Agent gateways** — the API gateway equivalent for multi-agent systems — have emerged as critical infrastructure. Solo.io's agentgateway, donated to the Linux Foundation in August 2025 and supported by AWS, Cisco, Microsoft, and IBM, provides AI-native protocol-aware routing for MCP and A2A traffic. Proofpoint's Secure Agent Gateway focuses specifically on data security in agentic workflows. Gartner explicitly identifies agent gateways as "the missing layer" for secure AI integration. Agent marketplaces are now operational at all major cloud providers, with AWS hosting 900+ listings and Oracle offering 100+ partner-built agent templates.

The **Agentic AI Foundation (AAIF)**, formed December 9, 2025 under the Linux Foundation with platinum members including Anthropic, Block, OpenAI, AWS, Bloomberg, Cloudflare, Google, and Microsoft, represents the industry's answer to fragmentation. It governs MCP, Block's goose framework, and OpenAI's AGENTS.md standard. Block's founding statement compared AAIF to "what the W3C is for the Web." Bloomberg's participation as a platinum member signals financial services directly — Bloomberg views MCP as the "essential connective layer for agentic AI systems for finance."

---

## Conclusion: the 18-month window that will define the decade

The agent-first paradigm represents a structural shift, not an incremental evolution. The convergence of MCP as the universal tool-connection standard, A2A for inter-agent communication, and the AAIF for governance is creating a protocol stack that will underpin the next generation of enterprise infrastructure. For financial services CISOs, several insights cut through the noise.

**Identity is the control plane.** Every other security concern — data loss, unauthorized access, supply chain integrity, regulatory compliance — flows through identity. Extending IAM to agents with the same rigor applied to human identities is the single highest-priority architectural decision. The Microsoft sponsor model, SPIFFE-based workload identity, and Okta's XAA protocol represent the three most mature approaches, and they are not mutually exclusive.

**The governance gap is the existential risk.** Banks are deploying agents at scale before governance frameworks exist to manage them. The CyberArk finding that fewer than 10% of organizations have deployed agentic security controls while nearly 40% of financial institutions already have agents in production describes a classic risk accumulation pattern. Gartner's prediction that over 40% of agentic AI projects will be canceled by 2027 is driven precisely by organizations that scaled adoption before establishing controls.

**The regulatory environment is catching up.** NIST's February 2026 AI Agent Standards Initiative, the EU AI Act's August 2026 enforcement deadline, and the FCA's Long Term Review all signal that agent governance obligations will be formalized within 12-18 months. Financial institutions that establish frameworks now — mapping to FINOS AI Governance Framework v2, OWASP Agentic Top 10, and NIST AI RMF — will have significant advantages over those forced to retrofit governance onto sprawling agent ecosystems.

**The attack surface is genuinely new.** Agent Session Smuggling, memory poisoning, delegation chain exploitation, and the systemic risk of model homogenization are not variations on known threats — they are architecturally novel attack vectors that require new detection capabilities, new threat models, and new security controls. The OWASP Agentic Top 10 and CSA MAESTRO framework provide starting taxonomies, but the threat landscape is evolving faster than the defense frameworks.

The organizations that move decisively in 2026 to establish agent identity architecture, deploy agent gateways with protocol-aware security, implement behavioral monitoring for agent populations, and engage actively with emerging standards bodies will define the governance patterns for the next decade. Those that wait face either competitive disadvantage or — worse — the systemic risk consequences of ungoverned autonomous agents operating at machine speed across critical financial infrastructure.